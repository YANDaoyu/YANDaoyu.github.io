---
layout: post
title: "U-Net for Biomedical Image Segmentation"
author: "Island"
categories: PaperReview
tags: [algorithm, DeepLearning]
---

> U-Net，一篇因为太多视频插帧论文提及所以才决定研习的论文，收录于2015年5月18日。然后发现这个论文还有别的基础论文。啊——

- [原文链接](https://arxiv.org/abs/1505.04597)
- [项目网址](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)
- [Ciresan的论文链接](http://people.idsia.ch/~juergen/nips2012.pdf)
- [Jonathan的FCN论文链接](https://arxiv.org/abs/1411.4038)
- 结构亮点：1)包含捕获内容的收缩路径和对称的用于精确定位的扩展路径；2)利用了之前网络提取的特征细化当前层的结果。

## 引言 Introduction
在遥远的那时候，用深度学习的方法分割医学图像，有几个事实：
1. 在这篇论文发表的时候，CNN通常还是只用来做分类的任务。
2. 生物医学图像数据比别的领域的图像数据匮乏一些。

针对1&2，Ciresan等人创造了一个网络[[1]](http://people.idsia.ch/~juergen/nips2012.pdf)，这个网络内置在一个滑动窗口中，每次读取一个小块并预测最中心的点的标签，当窗口滑动遍历完图像，整个图像的分割通过每个像素点的预测结果也就得到了。
![](/assets/img/UNet/Ciresan.jpg)

显然这个网络可以进行非常多组的网络训练（毕竟你切出来了那么多小块）。然而同样需要警醒的是，这个网络为了预测一个像素点的信息就输入了一个小块，导致了两个很大的缺点：1）运行完整张图会非常耗时；2）这样下来总体看来输入的小块与小块之间存在着很大的信息重叠而导致冗杂，可能导致过拟合。

换个思路，Jonathan等人提出了一个全卷积网络[[2]](https://arxiv.org/pdf/1411.4038.pdf)将所有的全连接层替换成了卷积层，最后再逐步上采样恢复原尺寸。
![](/assets/img/UNet/FCN.jpg)

本文就是基于这么一个全卷积的结构做的修改，造出了一个U型的网络结构来进行分割。可以看到，网络在上采样部分利用了之前收缩路径里的特征图，和现在的特征图联立在一起（FCN是逐点相加，具体细节可以看[ref.3](https://zhuanlan.zhihu.com/p/31428783)），直观感觉能比直接扩张可以得到更细节的结果。
![](/assets/img/UNet/UNet.jpg)


## 数据处理
### 有重叠的切片 Overlap-tile
因为卷积使用的方式是valid，所以网络的输出图像尺寸会略微小于输入的尺寸。本文提出了一个`overlap-tile`策略，旨在处理大尺寸的输入，又能保证训练的数据量在一定程度变大，并且这些数据也不是过于冗杂的。

所谓的`overlap-tile`策略，就是将大的医学图像无缝切割成很多小块，将每个小块作为网络的输入。显然这就使数据量增大了，也减轻了GPU显存的负担。不过之前也提到了，U-Net并不能保大小（比如在一个`3*3`的卷积核作用下，边界就有1个像素点宽度的丢失），所以在切割并传入网络之前，还需要将输入按照合理的尺寸，在周围一圈进行像素的镜像复制。
![](/assets/img/UNet/overlap-tile.jpg)
上图所示的就是如何进行镜像复制。在这个图里面，我们最初的输入大图区域是白色框`3m*2n`的这个块。为了保证最后输出的大小仍然为这个大小，我们有一种做法是加padding，不过在这里我们选择了**镜像**。   
举例说明：我们需要对黄色的这一个小块进行分割，即输出这么一个黄色的框`m*n`大小，我们计算知道需要蓝色框`(m+p)*(n+q)`这么大小的输入。那么为了保证整个图像在边界也没有损失，我们在边界上就应该添加镜像使输入大图尺寸变为`(3m+p)*(2n+q)`。这样，我们就可以将其切割成6个`(m+p)*(n*q)`的小块输入神经网络，然后得到6个`m*n`的输出，最后拼接成一个`3m*2n`的分割结果。    
可以看到，这样的小块与小块之间**仍然存在一定的重叠关系**，但是这相较于Ciresan的方法已经缓和了很多。因为尺寸的损失不是特别的大，我们大概率还是不会重叠一个区域太多次的。

### 弹性形变处理 Elastic Deformation
除去这种切割成小块的策略，作者还提出了弹性形变的处理方法，用以数据增强和提升网络学习形变不变性的能力。考虑到生物图像总是很容易发生形变，有这样的训练也是必要的。此处脑补一个百变怪。原文还提到学习不变性在无监督学习里面这个也有一定用处，指路[Dosovitsky的论文(我没看)](https://arxiv.org/abs/1406.6909v1)。
![](/assets/img/UNet/elastic.jpg)

所谓的弹性形变，大概是先做一个仿射变换，再叠加一个随机位移场。不过在这个文章里只是针对`3*3`的网格叠加了随机位移场，其中随机位移场的偏移量来自标准差$\sigma$为$10$的正态分布，具体每个像素的差值来自`bicubic`。

### 其他处理 Other Augmentation
这应当是和弹性形变对应，还有一些常见的平移和旋转。    
原文还提到了dropout可以在一定程度上委婉地表现数据增强，我对此持观望态度。

## 网络结构
![](/assets/img/UNet/UNet.jpg)

网络共有18+1层卷积，4层反卷积，4层池化。
网络进行了4次步长为2的`max-pooling`，即进行了4次缩小尺寸的过程，相应的也有4次`2*2`的反卷积恢复大小。其实结构是很清晰的，除了输出层为`1*1`卷积，剩余每层卷积都是`3*3`，激活函数为`ReLU`。    
这里我们看到，在反卷积以后，网络还联立了之前收缩路径里的结果，才进行下一步的卷积。这个思想其实在后来的研究里其实也是被多次使用的，**用原始的、比较包含底层细节的信息，去指导已经获得的更加高层的特征信息等**，在这里的话具体一点儿就是补充了细节的位置信息。

## 训练细节
这个训练有点过于🐂。尽管作者说是因为更偏好大的tile块（更少的重叠，但也导致了更少的数据量），所以它直接把  `batch_size`设置成了`1`，但我总悄悄怀疑是不是他们显存不够。下降方法是有动量的随机梯度下降，动量值是`0.99`，用这样大的动量值让下降的方向能够被之前的大量训练样本给束缚住。

损失函数是像素级的softmax函数（针对最终结果和真值计算）和一个权重函数的交叉熵。  
*疑问：尽管是个二元分类，但还是用的softmax？    
$p_k(x)=Softmax(x)=\frac{e^{a_k(x)}}{\sum^K_{k'} e^{a_{k'}(x)}}$，其中K为类别集，$a_k(·)$为像素点$x$在通道$k$上的激活函数。故而其实直接可以写成：
$$p_k(x)=\frac{e^{output_k(x)}}{e^{output_0(x)}+e^{output_1(x)}}, k\in\{0,1\}$$
记权重函数为$w(x)$，$\Omega$为图像域，$x$的正确标签为$gt(x)$，那么损失函数（加权交叉熵）为：

$$ E = \sum_{x\in\Omega}{w(x)p_{gt(x)}(x)}$$

关于这个权重函数，文中根据形态学（我的完全知识盲区，所以直接照搬了）预计算了一个权重图如下，其$w_c(x)$为一个平衡分类的权重图（没有找到明确值），$d_1(x)$为点到最近一个细胞边界的距离，$d_2(x)$为点到第二近的一个细胞边界的距离，$w_0=10, \sigma \approx 5$像素：

$$w(x) = w_c(x) + w_0 · \exp (-\frac{{(d_1(x)+d_2(x))}^2}{2\sigma^2})$$

如此我们就定义了整个训练过程的损失函数。
再用标准差$\sigma$为$\sqrt{2/N}$的高斯分布（正态分布）定义一下训练图的各个神经元间的权重参数，其中$N$为这个神经元前接的$nodes$数（比如这个神经元是由一个$3\times3$的卷积核在一个$64$通道的图上的来的，那么$N = 9 \times 64 =576$），我们整个训练就可以着手进行了。

## 训练结果 Results
测试了几个分割任务。
#### 电镜记录下神经结构的分割
数据来自2012年开始的ISBI的EM分割挑战，有30张512*512的图片和标注作为训练集，给了测试集的图片不过没有标注。通过三个error考量，明显优于了Ciresan等人提出的基于滑动窗口的模型，具体结果见下图：
![](/assets/img/UNet/table1.jpg)
#### 光镜下的细胞分割
数据来自2014年和2015年的ISBI细胞追踪挑战。    
Phc-U373包含35张部分有标注的图，得到的IOU(intersection over union)很不错，92%。   
DIC-HeLa的包含20张部分有标注的图，是玻璃平面上微分干涉对比的显微镜记录的HeLa细胞，IOU有77.5%。
![](/assets/img/UNet/table2.jpg)

## 快速回顾：
> 1. 通过`overlap-tile`和弹性形变增加了数据集
> 2. 基于FCN的模型将压缩路径的特征图再次和拓展路径的特征图concat以补充信息，某种意义上说也具有金字塔结构
> 3. 利用了形态学的方式定义了损失函数

存疑点：
1. `dropout`为什么被说委婉的数据增强？
2. 形态学到底是什么规则？
3. $w_c(·)$的定义从何而来？
4. IOU的意义是什么？

## 总结评价：
文章的意义大概在于较早提出了一个深度学习的分割模型，与FCN的像素直接相加补充之前的信息不通，选择了concat的形式补充低层信息，整体是具有金字塔结构的。这对数据量较少的领域或许意义更大，文中提出来的数据增强方法是有意义并且合理的。    
虽然更多的人称这个结构为"编码-解码"结构，但是我对此编码和解码领域并不是特别了解，因此不敢妄言。

---


Reference: 
1. [U-Net：用于生物医学图像分割的卷积网络-bySandaG](http://baijiahao.baidu.com/s?id=1600400677130320639&wfr=spider&for=pc)
2. [U-Net论文详解-by一个小迷糊66](https://blog.csdn.net/jianyuchen23/article/details/79349694)
3. [图像语义分割入门+FCN/U-Net网络解析](https://zhuanlan.zhihu.com/p/31428783)